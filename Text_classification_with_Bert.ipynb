{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text classification with Bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "19TXUiuROeguL-BpWH3W-WoZqsVwU3n9u",
      "authorship_tag": "ABX9TyPmhJZiOFtMLMHHkfhadwJ2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZF3fsf7Axxo"
      },
      "source": [
        "# Text classification on movie reviews Dataset from stanford with Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XZxdcVoEHf7"
      },
      "source": [
        "fig = dict({\n",
        "    \"data\": [{\"type\": \"bar\",\n",
        "              \"x\": [1, 2, 3],\n",
        "              \"y\": [1, 3, 2]}],\n",
        "    \"layout\": {\"title\": {\"text\": \"A Figure Specified By Python Dictionary\"}}\n",
        "})\n",
        "\n",
        "# To display the figure defined by this dict, use the low-level plotly.io.show function\n",
        "import plotly.io as pio\n",
        "\n",
        "pio.show(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l5pRX5u1xDG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07513c1b-e26c-4a4e-9c7b-e867b39a1d31"
      },
      "source": [
        "!mkdir  /content/drive/MyDrive/transformers_for_nlp\n",
        "%cd ./drive/MyDrive/transformers_for_nlp\n",
        "#from google.colab import files \n",
        "#files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/transformers_for_nlp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVEQWnnC1KSE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6264aeb4-9f37-4016-c4ce-673d3fc63c32"
      },
      "source": [
        "!pip install transformers\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 14.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 40.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 52.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=945a24c319af7633cb914104a249bcfc15131f5bee9afe9879604b723742058b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.44 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7R_MsQ51Sbf"
      },
      "source": [
        "# Downloading the dataset.\n",
        "!wget -q -nc http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHDlMAqd8ULs"
      },
      "source": [
        "# Unziping the dataset.\n",
        "!tar -zxf /content/drive/MyDrive/transformers_for_nlp/aclImdb_v1.tar.gz"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v3rD7pcAYDi",
        "outputId": "6d623015-2700-46dc-b778-ae70afb63ff0"
      },
      "source": [
        "!pip install -q git+https://github.com/gmihaila/ml_things.git\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 71kB 7.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.3MB 21.9MB/s \n",
            "\u001b[?25h  Building wheel for ml-things (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjftWj9fxn3U"
      },
      "source": [
        "import os\n",
        "import io\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import Dataset , DataLoader \n",
        "from ml_things import plot_dict , fix_text , plot_confusion_matrix\n",
        "from sklearn.metrics import classification_report , accuracy_score\n",
        "from transformers import (AutoConfig ,AutoModelForSequenceClassification ,AutoTokenizer,AdamW,\n",
        "                          get_linear_schedule_with_warmup , set_seed)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Mg42ILdD0IU"
      },
      "source": [
        "import torch\n",
        "from torch import nn \n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z63meho0a03C"
      },
      "source": [
        "set_seed(26)\n",
        "epochs = 4\n",
        "batches =  32 # as max seq length is small but for max _Seq_len =512 batch_Size should be very small (due togpu issues)\n",
        "max_seq_len = 50\n",
        "device =torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if device == 'cpu' :\n",
        "    print(\"Using cpu ,This will b slow\")\n",
        "model_name = 'bert_base_cased'\n",
        "\n",
        "labels = { \"pos\" : 1 , \"neg\" : 0}\n",
        "n_labels = len(labels)\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13lSCB4qa44L"
      },
      "source": [
        "class DataSet(Dataset):\n",
        "    r\"\"\"\n",
        "    This class can be used as is as long\n",
        "    as the `dataloader` outputs a batch in dictionary format that can be passed \n",
        "    straight into the model - `model(**batch)`.\n",
        " \n",
        "  Arguments:\n",
        " \n",
        "    path (:obj:`str`):\n",
        "        Path to the data partition.\n",
        "     \n",
        "    tokenizer (:obj:`transformers.tokenization_?`):\n",
        "        Transformer type tokenizer used to process raw text into numbers.\n",
        " \n",
        "    labels (:obj:`dict`):\n",
        "        Dictionary to encode any labels names into numbers. Keys map to \n",
        "        labels names and Values map to number associated to those labels.\n",
        " \n",
        "    max_sequence_len (:obj:`int`, `optional`)\n",
        "        Value to indicate the maximum desired sequence to truncate or pad text\n",
        "        sequences. If no value is passed it will used maximum sequence size\n",
        "        supported by the tokenizer and model.\n",
        "     \"\"\"\n",
        "    def _init__(self , path , tokenizer , labels , _max_seq_len):\n",
        "        super(DataSet,self).__init__()\n",
        "        if not os.path.isdir(path):\n",
        "             print(\"Path to directory does not exist.\")\n",
        "\n",
        "        texts = []\n",
        "        labels = []\n",
        "\n",
        "        #the labels are defined by folders with data we loop through each label.\n",
        "\n",
        "        for label , label_id in tqdm(labels.items()):\n",
        "             text_path  = os.path.join(path , label) #path/pos | path/neg\n",
        "\n",
        "             all_file_names = os.listdir(text_path)[:10] \n",
        "             for file_name in tqdm(all_file_names):\n",
        "                 file_path = os.path.join(text_path , file_name)\n",
        "\n",
        "                 text = io.open(file_path , mode = 'r' , encoding = 'utf-8').read()\n",
        "                 text = fix_text(text) #solves any encoding issues\n",
        "                 texts.append(text)\n",
        "                 labels.append(label_id)\n",
        "        self.n = len(labels)\n",
        "        #using tokenizer on text ,returns a dictionary with tokenized integer ids under input_ids key\n",
        "        self.tokenized_inputs = tokenizer(texts ,add_special_tokens = True , truncation = True, padding = True )\n",
        "        self.seq_len = self.tokenized_inputs['input_ids'].shape[-1] #length of sequence\n",
        "\n",
        "        self.tokenized_inputs.update({\"labels\" : torch.tensor(labels)})\n",
        "        print(self.tokenized_inputs)\n",
        "        def __len__(self) :\n",
        "            return self.n\n",
        "\n",
        "        def __getitem__(self , index):\n",
        "            r\"\"\"\n",
        "            Arguments:\n",
        " \n",
        "            index (:obj:`int`):\n",
        "                Index position to pick an example to return.\n",
        "        \n",
        "            Returns:\n",
        "            :obj:`Dict[str, object]`: Dictionary of inputs that feed into the model.\n",
        "            It holddes the statement `model(**Returned Dictionary)`.\n",
        "\n",
        "            \"\"\"\n",
        "            return {key : self.tokenized_inputs[key][items] for key in self.tokenized_inputs.keys()}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "oS-pbSv0aiKK",
        "outputId": "7d956397-df54-4162-f0dd-4373bf5cea92"
      },
      "source": [
        "d = Dataset(\"/content/drive/MyDrive/transformers_for_nlp/aclImdb/train\" , AutoTokenizer , labels , max_seq_len)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-de87d271da11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/transformers_for_nlp/aclImdb/train\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.7/typing.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, *args, **kwds)\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object.__new__() takes exactly one argument (the type to instantiate)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EUoXz8hh3oE1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld8TcReBb1OG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}